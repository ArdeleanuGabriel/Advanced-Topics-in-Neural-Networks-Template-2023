{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "a140223a",
      "metadata": {
        "id": "a140223a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Tuple\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "3e30c799",
      "metadata": {
        "id": "3e30c799"
      },
      "outputs": [],
      "source": [
        "def get_MNIST(path: str = \"./data\", train: bool = True, pin_memory: bool = True):\n",
        "  mnist_all = MNIST(path, download=True, train=train)\n",
        "  mnist_bits = []\n",
        "  mnist_target = []\n",
        "  for image, label in mnist_all:\n",
        "    #force from numpy\n",
        "    tensor = torch.from_numpy(np.array(image))\n",
        "    mnist_bits.append(tensor)\n",
        "    mnist_target.append(label)\n",
        "\n",
        "  mnist_bits = to_tensor(mnist_bits).float()#60000 x 28 x 28\n",
        "  mnist_bits = mnist_bits.flatten(start_dim=1)#60000 x 784\n",
        "  mnist_bits /= mnist_bits.max()#norm\n",
        "  mnist_target = to_tensor(mnist_target)#60000\n",
        "  if train:\n",
        "    mnist_target = to_one_hot(mnist_target)#6000 x 10\n",
        "  if pin_memory:\n",
        "    return mnist_bits.pin_memory(), mnist_target.pin_memory()\n",
        "  return mnist_bits, mnist_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "9c3504c0",
      "metadata": {
        "id": "9c3504c0"
      },
      "outputs": [],
      "source": [
        "def use_CPU_GPU():\n",
        "  #Avem GPU?\n",
        "  if torch.cuda.is_available():\n",
        "      return torch.device('cuda')\n",
        "  return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "763a556e",
      "metadata": {
        "id": "763a556e"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return z.sigmoid()\n",
        "\n",
        "def softmax(z):\n",
        "    return z.softmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "690d892f",
      "metadata": {
        "id": "690d892f"
      },
      "outputs": [],
      "source": [
        "def to_tensor(x):\n",
        "    if isinstance(x, (tuple, list)):\n",
        "        if isinstance(x[0], Tensor):\n",
        "            return torch.stack(x)\n",
        "        return torch.tensor(x)\n",
        "\n",
        "def to_one_hot(x):\n",
        "    return torch.eye(x.max() + 1)[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "e408edbd",
      "metadata": {
        "id": "e408edbd"
      },
      "outputs": [],
      "source": [
        "def forwardProp(x, weight, bias):\n",
        "    return torch.add(torch.mm(x, weight), bias)\n",
        "\n",
        "def backProp(x, y, y_h, y_o, w2):\n",
        "    Error_L2 = y_o - y #batch_size, 10\n",
        "    del_W2 = torch.mm(y_h.T, Error_L2) #100, batch_size, 10\n",
        "    del_B2 = Error_L2.mean(dim=0) #batch_size, 10\n",
        "\n",
        "    Error_L1 = y_h * (1 - y_h) * (torch.mm(w2, Error_L2.T)).T #batch_size, 100\n",
        "    del_W1 = torch.mm(x.T, Error_L1) #784, batch_size, 100\n",
        "    del_B1 = Error_L1.mean(dim=0) #batch_size, 100\n",
        "\n",
        "    return del_W1, del_B1, del_W2, del_B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "30d91466",
      "metadata": {
        "id": "30d91466"
      },
      "outputs": [],
      "source": [
        "def batch_training(x, y, w_ih, b_ih, w_ho, b_ho, mu):\n",
        "  #Input-Hidden\n",
        "  y_h = sigmoid(forwardProp(x, w_ih, b_ih))\n",
        "  #Hidden-Output\n",
        "  y_o = softmax(forwardProp(y_h, w_ho, b_ho))\n",
        "  #Loss\n",
        "  Loss = torch.nn.functional.cross_entropy(y_o, y)\n",
        "  #BackProp\n",
        "  del_W1, del_B1, del_W2, del_B2 = backProp(x, y, y_h, y_o, w_ho)\n",
        "  #New Values\n",
        "  w_ih -= mu * del_W1\n",
        "  b_ih -= mu * del_B1\n",
        "  w_ho -= mu * del_W2\n",
        "  b_ho -= mu * del_B2\n",
        "\n",
        "  return w_ih, b_ih, w_ho, b_ho, Loss\n",
        "\n",
        "def epoch_training(data, labels, w_ih, b_ih, w_ho, b_ho, mu, batch_size):\n",
        "  non_blocking = w_ih.device.type == 'cuda'\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i in range(0, data.shape[0], batch_size):\n",
        "    x = data[i: i + batch_size].to(w_ih.device, non_blocking=non_blocking)\n",
        "    y = labels[i: i + batch_size].to(w_ih.device, non_blocking=non_blocking)\n",
        "    w_ih, b_ih, w_ho, b_ho, batch_loss = batch_training(x, y, w_ih, b_ih, w_ho, b_ho, mu)\n",
        "    epoch_loss += batch_loss\n",
        "\n",
        "  return w_ih, b_ih, w_ho, b_ho, epoch_loss / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "ecc00858",
      "metadata": {
        "id": "ecc00858"
      },
      "outputs": [],
      "source": [
        "def test(bits, targets, w_ih, b_ih, w_ho, b_ho, batch_size):\n",
        "  Total_corect = 0\n",
        "  Total = bits.shape[0]\n",
        "  non_blocking = w_ih.device.type == 'cuda'\n",
        "\n",
        "  for i in range(0, Total, batch_size):\n",
        "    x = bits[i: i + batch_size].to(w_ih.device, non_blocking=non_blocking)\n",
        "    y = targets[i: i + batch_size].to(w_ih.device, non_blocking=non_blocking)\n",
        "    result = softmax(forwardProp(sigmoid(forwardProp(x, w_ih, b_ih)), w_ho, b_ho))\n",
        "\n",
        "    resulted_max_value, resulted_max_value_indices = torch.max(result, dim=1)\n",
        "    bool_mask = resulted_max_value_indices == y\n",
        "    correct_predictions = bool_mask.sum().item()\n",
        "    Total_corect += correct_predictions\n",
        "\n",
        "  return Total_corect / Total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "b9ff903f",
      "metadata": {
        "id": "b9ff903f"
      },
      "outputs": [],
      "source": [
        "def train(epochs, device: torch.device = use_CPU_GPU()):\n",
        "\n",
        "  pin_memory = device.type == 'cuda'\n",
        "  w_ih = torch.normal(0, 1 / np.sqrt(784) , (784, 100), device=device)\n",
        "  b_ih = torch.zeros((1, 100), device=device)\n",
        "  w_ho = torch.normal(0, 1 / np.sqrt(784), (100, 10), device=device)\n",
        "  b_ho = torch.zeros((1, 10), device=device)\n",
        "  mu = 0.01\n",
        "  batch_size = 60\n",
        "  test_batch_size = 500\n",
        "  bits_train, targets_train = get_MNIST(train=True, pin_memory=pin_memory)\n",
        "  bits_test, targets_test = get_MNIST(train=False, pin_memory=pin_memory)\n",
        "  total_loss = 0\n",
        "  for epoch in range(epochs):\n",
        "    print(epoch)\n",
        "    epoch_loss = 0\n",
        "    w_ih, b_ih, w_ho, b_ho, epoch_loss = epoch_training(bits_train, targets_train, w_ih, b_ih, w_ho, b_ho, mu, batch_size)\n",
        "    total_loss += epoch_loss\n",
        "    accuracy = test(bits_test, targets_test, w_ih, b_ih, w_ho, b_ho, test_batch_size)\n",
        "  print(\" Folosind: \"+ str(device) + \" Precizia = \" + str(accuracy) + \" Loss-epoci = \" + str(epoch_loss) + \" Loss-Total = \" + str(total_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "d62dd284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62dd284",
        "outputId": "191602a1-ecc6-473f-c23c-99c757cb6646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            " Folosind: cpu Precizia = 0.9799 Loss-epoci = tensor(24.4111) Loss-Total = tensor(1235.9165)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            " Folosind: cpu Precizia = 0.9793 Loss-epoci = tensor(24.4105) Loss-Total = tensor(1235.9904)\n"
          ]
        }
      ],
      "source": [
        "train(50, torch.device('cpu'))\n",
        "train(50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}